{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayalenE/simple-foc-assistant/blob/main/SimpleFOC_AI_Assistant_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWiBVBuOUm-G"
      },
      "source": [
        "# Building a SimpleFOC AI Assistant with Retrieval Augmented Generation (RAG)\n",
        "\n",
        "Mayalen Etcheverry | April, 2024\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/mayalenE/simple-foc-assistant/blob/main/SimpleFOC_AI_Assistant_RAG.ipynb\" target=\"_blank\" id=\"colablink\" class=\"colab-root\"><span id=\"reprotext\">Reproduce in </span><span class=\"colab-span\">Notebook</span></a>\n",
        "<a href=\"https://github.com/mayalenE/simple-foc-assistant\" target=\"_blank\" id=\"colablink\" class=\"colab-root\"><span id=\"reprotext\">Github </span><span class=\"github-span\">Repository</span></a>\n",
        "\n",
        "[TOC]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcnKnHwcxfjl"
      },
      "source": [
        "## What is SimpleFOC?\n",
        "\n",
        "<img src=\"https://repository-images.githubusercontent.com/173681491/717e1b00-8c9f-11ea-83f4-513489af9d3b\" alt=\"SimpleFOC\" width=\"400\"/>\n",
        "\n",
        "The [SimpleFOC library](https://github.com/simplefoc/Arduino-FOC) is an open-source library for controlling brushless DC (BLDC) motors with Field Oriented Control (FOC) algorithms. [Brushless motor control is awesome for robotics](https://www.youtube.com/watch?v=-mLuU1Nscu4) but it can be quite hard to understand and implement in practice, and existing solutions are often very specific to certain (expensive) hardware configurations. SimpleFOC has gained increasing popularity within the hobby community because it provides an open-source and user-friendly library to facilitate BLDC motor control for a wide variety of motor + driver + sensor + microcontroller combinations, including low-cost ones, which has led to its widespread usage by the community hence to some amazing [projects](https://www.youtube.com/watch?v=WLkLe2-GfXE) 🤖"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKAL2yXrxfp9"
      },
      "source": [
        "## Why a SimpleFOC AI Assistant?\n",
        "\n",
        "As the community grows, there are more and more questions that pop up into the [SimpleFOC community forum](https://community.simplefoc.com/) spanning various queries such as resolving potential hardware or installation issues, asking for advice in choosing the right setup, understanding bugs in one's code, etc. While those questions can be very diverse and some of them can be hard to answer, even for the expert members of the SimpleFOC community, there also are questions for which the answers can often be found already online, notably in the [SimpleFOC documentation](https://docs.simplefoc.com/) (or in other online resources). However for users it can be quite complicated or time-expensive to directly search for information in the SimpleFOC or other support docs as these documentations can become quite long and hard to parse, especially for beginners. This is where an AI Assistant could be very handy: the user could directly ask question in natural language form to the AI assistant, which could go and retrieve the relevant information from these docs automatically, and then communicate it back to the user into a comprehensive and concise manner, redirecting toward useful resources when necessary.\n",
        "\n",
        "This is exactly what we are going to try to build in this notebook. To do so, we'll see how we can turn a general LLM assistant (such as Mistral models) into a customized SimpleFOC assistant without having to re-train the weights of the networks nor having to do any kind of heavy computation. Instead, we'll simply provide the LLM with relevant information from the SimpleFOC docs as input so that the LLM can tailor its answers in a meaningful manner. This simple and neat idea is called *Retrieval Augmented Generation*, or RAG in short, and was proposed by Lewis et al. back in 2020 in [this paper](https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html). The code is based on *open-source* packages and LLM weights (quantized mistral-instruct) and should be *easy-to-run*, e.g. directly in colab with a T4 free-access gpu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlKHZ3aPZgAi"
      },
      "source": [
        "## Retrieval Augmented Generation\n",
        "\n",
        "Let's start by decorticating the basic ideas behind R-A-G 👇\n",
        "\n",
        "* Retrieval: we want to *retrieve relevant information* given an input query. In our case, an input query would come from a user of the SimpleFOC community and could for instance ask \"What are the supported position sensors with simplefoc?\" or \"Can esp8266 chip be used to drive 6pwm drivers with simplefoc?\"\n",
        "* Augmented: The way this information is passed to the LLM is simply by *augmenting the prompt* with that retrieved knowledge\n",
        "* Generation: retrieval augmentation is fed as inputs to the LLM which returns *generative outputs*, as usual with LLMs.\n",
        "\n",
        "\n",
        "Why RAG could be useful to construct our SimpleFOC AI Assistant?\n",
        "\n",
        "Well first, mainstream AI assistants such as variants of GPT, LLama and Mistrals tend to return *generic* information, as they are trained from massive amount of data from the internet. In our target use-case questions will be specific to details of the SimpleFOC library and we want the answer to communicate the true information from SimpleFOC support and docs, or at least to communicate uncertainty when it cannot find the answer within the docs. Yet, this is not the case when using off-the-shelf LLMs, despite the fact that it is very likely that SimpleFOC docs, which are hosted on github, have been part of the training data of these LLMs.\n",
        "\n",
        "For instance let's have a look of what ChatGPT 4 answers to some questions SimpleFOC users might have:\n",
        "\n",
        "\n",
        "> **User:**\n",
        ">> Can esp8266 chip be used to drive 6pwm drivers with simplefoc?\n",
        "\n",
        "> **ChatGPT:**\n",
        ">> The ESP8266 chip can indeed be used to drive motors using PWM (Pulse Width Modulation), and integrating it with the SimpleFOC (Field Oriented Control) library is technically feasible for controlling brushless motors with precision. However, there are a few considerations to keep in mind when attempting to use it to drive 6 PWM drivers:\n",
        "\n",
        ">>> **1. GPIO Pins:** The ESP8266 has a limited number of GPIO pins available for use, and not all of them can be used for PWM output. You'll need to ensure that the ESP8266 module you're using has enough PWM-capable GPIO pins for your application. For 6 PWM drivers, you'll need at least 6 PWM-capable pins, assuming one PWM signal per driver.\n",
        "\n",
        ">>> **2. PWM Channels:** The ESP8266 hardware supports a limited number of PWM channels. This limitation can sometimes be circumvented by software PWM libraries, but this might introduce limitations in terms of performance and accuracy. It's crucial to check if the PWM resolution and frequency meet your requirements for motor control.\n",
        "\n",
        ">>> **3. Processing Power and Timing:** The ESP8266 is quite capable in terms of processing power for many applications, but running sophisticated control algorithms like those required for precise motor control with SimpleFOC on 6 motors simultaneously might push its limits, especially if other tasks (like Wi-Fi communication) are being performed. Timing precision is vital for motor control, and the ESP8266's multitasking environment might introduce jitter.\n",
        "\n",
        ">>> **4. SimpleFOC Library Compatibility:** The SimpleFOC library is designed to be hardware-agnostic, but its performance and the features available can vary significantly between different microcontroller platforms. Ensure that the library supports the ESP8266 with the features you need, especially regarding the number of motors and the control precision.\n",
        "\n",
        ">>> **5. Power Supply and Driver Compatibility:** Make sure that your motor drivers are compatible with the PWM signal levels of the ESP8266 and that they can handle the required power levels for your motors.\n",
        "\n",
        ">> For a project driving 6 PWM drivers with an ESP8266 using SimpleFOC, you might need to carefully manage resources, possibly modify the library for better compatibility, or use additional hardware like PWM expanders. It's also a good idea to look into the community forums or documentation for any similar projects or guidance specific to your application needs.\n",
        "\n",
        "\n",
        "👉 A first problematic here is that the answer from GPT tend to be quite long and generic, whereas this question rather expects some YES or NO answer.\n",
        "\n",
        "👉 Moreover, if we take the time to read the answer we get the understanding that YES it is possible to use an ESP8266 microcontroller be to drive 6pwm drivers with simplefoc. Unfortunately, as reported in [this table](https://docs.simplefoc.com/microcontrollers#choosing-the-microcontroller) of SimpleFOC docs, this is not true.\n",
        "This issue, often called **hallucination**, is a well-known limitation of LLMs: LLMs can generate \"good looking\" text that sounds convincing, but it does not mean that it is true or factual, which is something that we want to remedy in our target use-case.\n",
        "\n",
        "\n",
        "Let's look at another question that a user might have, to which we add *\"Give a concise answer based on the simpleFOC documentation\"* to avoid too lenghty answers, and see how ChatGPT 4 answers it:\n",
        "\n",
        "\n",
        "> **User:**\n",
        ">> User\n",
        "Simplefoc compiles and I flush it to my board, but nothing moves. I use platformio, what could be the problem? Give a concise answer based on the simpleFOC documentation.\n",
        "\n",
        "> **ChatGPT:**:\n",
        ">> If SimpleFOC compiles and you've flashed it to your board but nothing moves, the issue could stem from a few common areas according to the SimpleFOC documentation. Here's a concise checklist of things to verify:\n",
        "\n",
        ">>> 1. **Wiring and Connections**: Ensure all connections are secure and correctly wired, including the motor to the driver, the driver to the microcontroller, and any sensors you are using.\n",
        "\n",
        ">>> 2. **Motor and Driver Compatibility**: Verify that the motor is compatible with the driver you're using and that the driver can handle the motor's current and voltage requirements.\n",
        "\n",
        ">>> 3. **Power Supply**: Ensure that the power supply is adequate for your motor and driver. It should meet the voltage and current requirements of your system.\n",
        "\n",
        ">>> 4. **Configuration and Calibration**: Check if the motor, driver, and any sensor configurations in your code match your hardware setup. This includes motor parameters (pole pairs, current limit, etc.) and sensor calibration if using encoders or other position sensors.\n",
        "\n",
        ">>> 5. **Code Upload**: Confirm that the code has been successfully uploaded to the board. Sometimes, the upload process might appear successful, but issues like incorrect board settings in PlatformIO can cause the firmware not to run as expected.\n",
        "\n",
        ">>> 6. **Motor Control Code**: Ensure that your motor control code (loop) is correctly implemented. This includes initializing the motor and driver, setting the target value (velocity, position, or torque), and periodically updating the motor controller in your loop.\n",
        "\n",
        ">>> 7. **Debugging**: Use serial print statements to debug your code. Check for any errors or warnings during initialization and operation. Verify that the sensor readings (if applicable) are reasonable and that the control loop is active.\n",
        "\n",
        ">> If after checking these areas the problem persists, consulting the SimpleFOC community forum or GitHub issues page may provide additional insight or solutions specific to your hardware setup and application.\n",
        "\n",
        "\n",
        "👉 Again we have a generic answer with generic recommandations and misses to answer with specific relevant information from the SimpleFOC resources. Yet, there is a very common explanation to the issue raised by this user when using PlatformIO with SimpleFOC which is to not forget to add the `lib_archive=False` option to the `platfromio.ini` file as well explained [here](https://docs.simplefoc.com/library_platformio) in the docs and as commonly reminded in the [SimpleFOC forum](https://community.simplefoc.com/search?q=platformio%20lib_archive). We would like the AI Assistant to remind this to the user and to emphasize is as possible cause for the error.\n",
        "\n",
        "\n",
        "\n",
        "In summary, RAG should a priori be useful in two ways:\n",
        "\n",
        "1. RAG can help prevent hallucinations by prompting the LLM with information based on relevant passages from the docs that are factual.\n",
        "\n",
        "2. RAG can help specify the responses with information coming from actual data, offering more interpretability as we know where the generations came from, instead of providing generic responses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8dBd1ufZEAA"
      },
      "source": [
        "## RAG Pipeline\n",
        "\n",
        "![pipeline](https://raw.githubusercontent.com/mayalenE/simple-foc-assistant/main/rag-pipeline.png)\n",
        "\n",
        "As summarized in the above figure, we are going to follow the following steps\n",
        "in this notebook:\n",
        "\n",
        "1. Download the SimpleFOC documentation (collection of markdown files)\n",
        "2. Format and pre-process the documentation into chuncks of tokens\n",
        "3. Embed all of the chunks into numerical reprentations (embedding) using an **Embedding Model**\n",
        "4. Setup a retrieval system that uses **Vector Search** to find relevant chunks of text based on a query\n",
        "5. Create a prompt that augment the original query with the retrieved pieces of text\n",
        "6. Use an existing LLM (e.g. quantized mistral-instruct) to generate an answer to the augmented prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpQbu4TyZEGM"
      },
      "source": [
        "## Main Design Choices 💡\n",
        "\n",
        "The below table recaps the main design choices that we have to care about when implementing a RAG pipeline, as they can largely influence the resulting outputs 👇\n",
        "\n",
        "\n",
        "| **Design Choice** | **Impact** |\n",
        "| ----- | ----- |\n",
        "| **Chunking the data** | 1) The way we generate chunks will directly influence the results: it is usually done with a fixed-size overlapping sliding window <br> but more advanced strategies of chunking could be envisaged such as recursive or semantic chunking as explained in [this video](https://www.youtube.com/watch?v=8OJC21T2SL4) <br> 2) The length of the chunks will also influence the results: smaller chunks will lead to more precise context but might miss important <br> information whereas larger chunks might hide relevant fine-grained info, and the length is limited by the LLM context length. <br> 3) How we preprocess the data before chunking is also one thing to consider as we want to remove non-useful information/tokens |\n",
        "| **Embedding model** | The choice of the embedding model will determine which chunks of text are considered similar (in meaning) to the input query, <br> which will have a direct impact on what information is retrieved from the vector database. |\n",
        "| **Similarity search** | To find chunks relevant to the query, Vector search is often used to find vectors that are the closest in the high-demensional embedding space. <br> Design choices include the similarity score measure, which is usually a simple dot product or cosine similarity, as well as the number of retrieved tokens. <br> One could also consider replacing pure vector/semantic search with a hybrid of vector search and keyword-based search. |\n",
        "| **Large Language Model (LLM)** | Obviously the choice of the base LLM will highly impact the final results given the same RAG context and input prompt. <br> I do not have a proper tip to choose the right LLM, except that it is usually quite constrain by the hardware setup at your disposal. <br> The LLM context window, number of tokens that a LLM can accept as input, can also condition the choice, in particular for<br> the RAG pipeline where the context window will directly determine the number of reference items we can feed to the LLM. <br> I usually like to go for small open-source models because they are easy to play with. |\n",
        "| **Base Prompt** | Finally, an important design choice is how we will do \"[prompt engineering](https://en.wikipedia.org/wiki/Prompt_engineering)\" to structure the base prompt that we will augment <br> with the retrieved items, and then feed as input to the generative LLM together. The aim here is for the generated output to look <br> as close as possible to what an ideal SimpleFOC AI Assistant should answer.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NVIJrdDVfPN"
      },
      "source": [
        "## Let's implement it! 💻"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imVTIbGDUsRt"
      },
      "source": [
        "### Installs\n",
        "\n",
        "We'll be using the [LlamaIndex](https://docs.llamaindex.ai/en/stable/) library 🦙, that as you will see makes it very easy to implement context augmentation for LLMs with only few lines of code. We also need to install the [llama-index-embeddings-huggingface](https://docs.llamaindex.ai/en/stable/examples/embeddings/huggingface/) library in order to be able to load embedding models from the HuggingFace [embedding leaderboard](https://huggingface.co/spaces/mteb/leaderboard) 🤗, as well as Hugging Face [transformers](https://huggingface.co/docs/transformers/en/index) and [optimum](https://huggingface.co/docs/optimum/index) libraries enabling us to load and use state-of-the art pretrained models efficiently. We additionally install [auto-gptq](https://github.com/AutoGPTQ/AutoGPTQ) library, as we'll load quantized versions of LLMs for even higher efficiency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFwm7wDSoF3V"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers optimum\n",
        "!pip install -q llama-index\n",
        "!pip install -q llama-index-embeddings-huggingface\n",
        "!pip install -q auto-gptq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAm7zPjjHvEJ"
      },
      "source": [
        "### 1) Loading the SimpleFOC data\n",
        "\n",
        "Let's create the folder where we are going to download the documents that we'll use for RAG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80CxhqQJXSLT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(\"data/\", exist_ok=True) #ignore if data folder already exists"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEuo9zQIWkRO"
      },
      "source": [
        "#### Download SimpleFOC Docs\n",
        "\n",
        "Let's start by downloading the docs from SimpleFOC documentation [https://docs.simplefoc.com/](https://docs.simplefoc.com/).\n",
        "\n",
        "Instead of using the web-rendered documentation, we'll download the original files written in Makdown format that can be found [here](https://raw.githubusercontent.com/simplefoc/simplefoc.github.io/master/docs/simplefoc_library/) on github. We are gonna iterate over all the files in this folder, and save them locally in our `data` folder. We do a bit of pre-processing by removing the markdown headers as they we are interested only in the content of the files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP0EbcTbTFHb",
        "outputId": "6c8d485a-1ffc-4074-d74b-a3b469062d64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "105it [00:00, 106.86it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import urllib3\n",
        "\n",
        "for i, doc_fn in tqdm(enumerate(['work_roadmap.md',\n",
        " 'index.md',\n",
        " 'hardware/sensors.md',\n",
        " 'hardware/index.md',\n",
        " 'hardware/motors/index.md',\n",
        " 'hardware/motors/BLDC_motors.md',\n",
        " 'hardware/motors/phase_resistance.md',\n",
        " 'hardware/motors/stepper_motors.md',\n",
        " 'hardware/drivers/BLDC_drivers.md',\n",
        " 'hardware/drivers/stepper_drivers.md',\n",
        " 'hardware/drivers/index.md',\n",
        " 'hardware/mcus/rpi_pico.md',\n",
        " 'hardware/mcus/teensy.md',\n",
        " 'hardware/mcus/portenta.md',\n",
        " 'hardware/mcus/stm32.md',\n",
        " 'hardware/mcus/arduinos.md',\n",
        " 'hardware/mcus/index.md',\n",
        " 'hardware/mcus/esp32.md',\n",
        " 'hardware/mcus/samd.md',\n",
        " 'hardware/mcus/nRF52_mcu.md',\n",
        " 'hardware/setup_examples/nucleo_conneciton.md',\n",
        " 'hardware/setup_examples/arduino_l6234.md',\n",
        " 'hardware/setup_examples/hmbgc.md',\n",
        " 'hardware/setup_examples/drv8302.md',\n",
        " 'hardware/setup_examples/index.md',\n",
        " 'hardware/setup_examples/bluepill_conneciton.md',\n",
        " 'hardware/setup_examples/foc_shield.md',\n",
        " 'digging_deeper/index.md',\n",
        " 'digging_deeper/libray_source/foc_source.md',\n",
        " 'digging_deeper/libray_source/sensors.md',\n",
        " 'digging_deeper/libray_source/index.md',\n",
        " 'digging_deeper/libray_source/examples.md',\n",
        " 'digging_deeper/libray_source/communication.md',\n",
        " 'digging_deeper/libray_source/motiron_control.md',\n",
        " 'digging_deeper/theory/index.md',\n",
        " 'digging_deeper/theory/voltage_torque_control.md',\n",
        " 'digging_deeper/theory/pid_controller.md',\n",
        " 'digging_deeper/theory/FOC_routine.md',\n",
        " 'digging_deeper/theory/low_pass_filtering.md',\n",
        " 'code/index.md',\n",
        " 'code/monitoring.md',\n",
        " 'code/from_scratch.md',\n",
        " 'code/debug.md',\n",
        " 'code/sensors/hall_sensor.md',\n",
        " 'code/sensors/generic.md',\n",
        " 'code/sensors/encoder.md',\n",
        " 'code/sensors/index.md',\n",
        " 'code/sensors/magnetic/magnetic_sensor_i2c.md',\n",
        " 'code/sensors/magnetic/magnetic_sensor_pwm.md',\n",
        " 'code/sensors/magnetic/index.md',\n",
        " 'code/sensors/magnetic/magnetic_sensor_spi.md',\n",
        " 'code/sensors/magnetic/magnetic_sensor_analog.md',\n",
        " 'code/motion_control/index.md',\n",
        " 'code/motion_control/open_loop/angle_openloop.md',\n",
        " 'code/motion_control/open_loop/index.md',\n",
        " 'code/motion_control/open_loop/index_search.md',\n",
        " 'code/motion_control/open_loop/velocity_openloop.md',\n",
        " 'code/motion_control/closed_loop_control/velocity.md',\n",
        " 'code/motion_control/closed_loop_control/index.md',\n",
        " 'code/motion_control/closed_loop_control/angle.md',\n",
        " 'code/motion_control/closed_loop_control/torque_control/foc_current.md',\n",
        " 'code/motion_control/closed_loop_control/torque_control/index.md',\n",
        " 'code/motion_control/closed_loop_control/torque_control/voltage.md',\n",
        " 'code/motion_control/closed_loop_control/torque_control/dc_current.md',\n",
        " 'code/motors/index.md',\n",
        " 'code/motors/bldc_motors.md',\n",
        " 'code/motors/stepper_motors.md',\n",
        " 'code/drivers/index.md',\n",
        " 'code/drivers/bldc_driver/bldc_driver_3pwm.md',\n",
        " 'code/drivers/bldc_driver/index.md',\n",
        " 'code/drivers/bldc_driver/bldc_driver_6pwm.md',\n",
        " 'code/drivers/stepper_driver/stepper_driver_4pwm.md',\n",
        " 'code/drivers/stepper_driver/index.md',\n",
        " 'code/drivers/stepper_driver/stepper_driver_2pwm.md',\n",
        " 'code/current_sense/high_side.md',\n",
        " 'code/current_sense/index.md',\n",
        " 'code/current_sense/low_side.md',\n",
        " 'code/current_sense/inline.md',\n",
        " 'code/communication/index.md',\n",
        " 'code/communication/step_dir.md',\n",
        " 'code/communication/commander/index.md',\n",
        " 'code/communication/commander/custom.md',\n",
        " 'code/communication/commander/pid.md',\n",
        " 'code/communication/commander/scalar.md',\n",
        " 'code/communication/commander/lpf.md',\n",
        " 'code/communication/commander/motion.md',\n",
        " 'code/communication/commander/motor.md',\n",
        " 'examples/position_control_example.md',\n",
        " 'examples/position_control_example_nucleo.md',\n",
        " 'examples/drv8302.md',\n",
        " 'examples/index.md',\n",
        " 'examples/foc_pendulum.md',\n",
        " 'examples/haptics.md',\n",
        " 'examples/position_control_example_mini.md',\n",
        " 'examples/position_control_example_mini_nucleo.md',\n",
        " 'examples/velocity_control_example.md',\n",
        " 'examples/gimbal_velocity_example.md',\n",
        " 'examples/stepper_control_nucleo.md',\n",
        " 'installation/minimal_download.md',\n",
        " 'installation/index.md',\n",
        " 'installation/library_platformio.md',\n",
        " 'installation/library_download.md',\n",
        " 'cheatsheet/index.md',\n",
        " 'cheatsheet/build_flags.md',\n",
        " 'cheatsheet/options.md'])):\n",
        "\n",
        "    doc_url = f\"https://raw.githubusercontent.com/simplefoc/simplefoc.github.io/master/docs/simplefoc_library/{doc_fn}\"\n",
        "    resp = urllib3.request(\"GET\", doc_url)\n",
        "\n",
        "    if resp.status == 200:\n",
        "        doc_fp = f\"data/doc_{i:04d}.txt\"\n",
        "        doc_str = resp.data.decode(\"utf-8\")\n",
        "\n",
        "        # remove the header\n",
        "        header, content = doc_str.split(\"\\n---\\n\")\n",
        "\n",
        "        if not os.path.exists(doc_fp):\n",
        "            with open(doc_fp, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PcBI3_cXSS4"
      },
      "source": [
        "#### [Optional] SimpleFOC Discourse\n",
        "\n",
        "There is also the SimpleFOC community forum [https://community.simplefoc.com/](https://community.simplefoc.com/) that is hosted on discourse and provides useful information. The forum has many topics and can be quite long to dowload so we are gonna skip this for the moment, but if you are interested in including it you can set `load_discourse=True` in the below cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pM8zP8yRWi6H"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "\n",
        "discourse_url = \"https://community.simplefoc.com/\"\n",
        "load_discourse = False\n",
        "\n",
        "if load_discourse:\n",
        "\n",
        "    # already downloaded files\n",
        "    data_list =  glob.glob('./data/discourse_*.txt')\n",
        "    data_list = sorted(data_list, key=lambda x:int(x[-8:-4]))  # sort data according to topic id\n",
        "    last_topic_id = 0 if len(data_list)==0 else int(data_list[-1][-8:-4]) # last topic that have been downloaded locally\n",
        "\n",
        "    # download novel topics\n",
        "    max_topic_id = 4631 # increase if needed\n",
        "    for i in tqdm(range(last_topic_id, max_topic_id)):\n",
        "\n",
        "        topic_url = discourse_url + f\"raw/{i}\"\n",
        "        resp = urllib3.request(\"GET\", topic_url)\n",
        "\n",
        "        if resp.status == 200:\n",
        "\n",
        "            topic_fp = f\"data/discourse_{i:04d}.txt\"\n",
        "\n",
        "            topic_str = resp.data.decode(\"utf-8\")\n",
        "\n",
        "\n",
        "            if not os.path.exists(topic_fp):\n",
        "\n",
        "                # filter topics if it has only one non-empty post\n",
        "                topic_posts = topic_str.split(\"\\n-------------------------\\n\")\n",
        "                topic_posts.remove(\"\\n\")\n",
        "                if len(topic_posts) <= 2:\n",
        "                    continue\n",
        "\n",
        "                # save topic_posts as doc\n",
        "                else:\n",
        "                    with open(topic_fp, \"w\", encoding=\"utf-8\") as f:\n",
        "                        f.write(topic_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ2KcMi7a2L9"
      },
      "source": [
        "#### Loading Data into LlamaIndex\n",
        "\n",
        "We can now load data from our local `data` folder into LlamaIndex using the `SimpleDirectoryReader` class which supports many file formats, including markdown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjJGLbLta2UB",
        "outputId": "0645677c-d67b-4841-c915-d1a3a8b7f722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "105\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "reader = SimpleDirectoryReader(input_dir=\"./data\")\n",
        "documents = reader.load_data()\n",
        "print(len(documents))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTm2JQk3Eezl"
      },
      "source": [
        "### 2) Process data as chunks of tokens\n",
        "\n",
        "LlamaIndex will take care of everything for step 2, 3 and 4, such that we only need to specify the desired hyperparameters for those steps.\n",
        "\n",
        "For step 2, pre-processing the data into chunks, we simply use a fixed-sized overlapping window method, dividing the text into chunks of fixed number of characters specified with `chunk_size` and overlapping by `chunk_overlap` characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnO-P1nBaI8l"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.chunk_size = 512\n",
        "Settings.chunk_overlap = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gZ18Ss-E5xG"
      },
      "source": [
        "### 3) Embed chunks into a VectorDB\n",
        "\n",
        "Embedding is simply turning the chunks of text into numerical representations (embeddings). Note that these embeddings are *learned* representation vectors lying in high-dimensional space that capture semantic information of the words or phrases.\n",
        "\n",
        "There are many embedding models that are available on the HF hub. A good ressource to choose a model is to check the [Massive Text Embedding Benchmark (MTEB) Leaderboard](https://huggingface.co/spaces/mteb/leaderboard) which lists the current best text embedding models out there on a variety of tasks. To select a proper embedding model you generally want to have a look at:\n",
        "\n",
        "* Model Size (number of parameters): known only for open models, but this will impact speed/memory and we want to keep that relatively small in order to be able to run it fast on colab GPUs\n",
        "* Embedding Dimension: dimensionality of the vector embedding\n",
        "* Max tokens: max number of tokens that fit into the LLM input prompt, depending on this you will have to adapt the chunk size\n",
        "* performance on tasks such that classification, clustering, retrieval, etc.\n",
        "\n",
        "Here we'll be using the [mxbai-embed-large-v1](https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1) model by mixed-bread-ai, which has 335M params, an embedding dimension of 1024 and can take a maximum of 512 tokens as input (which is exactly what we used as our chunk size).\n",
        "\n",
        "Once you have selected an embedding model from the HF hub, you simply need to specify it using the `embed_model` setting and `HuggingFaceEmbedding` wrapper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBuIj8Xzqb6A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff398718-8a50-43b4-b5c1-628d75e9a58c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "Settings.embed_model = HuggingFaceEmbedding(model_name=\"mixedbread-ai/mxbai-embed-large-v1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRNAxGNDhpV7"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "index = VectorStoreIndex.from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKnaw_GjE6GC"
      },
      "source": [
        "### 4) Setup a retrieval system using Vector Search\n",
        "\n",
        "For step 4, LlamaIndex is again taking care of everything to build a query engine using Vector Search, we simply need to explicitly disable the use of OpenAI LLM (we will use a small open-source one in Step 6) and  need to specify is the desired `similarity_top_k` setting. Here we use `similarity_top_k=3`, meaning that we will retrieve the 3 closest embeddings from our VectorDB given the user's query embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzCFI4-ghrIl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f9682ab-5d2c-4d0d-e0dd-2d1cfd6ae0ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM is explicitly disabled. Using MockLLM.\n"
          ]
        }
      ],
      "source": [
        "Settings.llm = None\n",
        "\n",
        "similarity_top_k = 3\n",
        "query_engine = index.as_query_engine(similarity_top_k=similarity_top_k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRixLzNZ88mQ"
      },
      "source": [
        "Let's have a look at which chunks our query engine returns given the following user query *\"Simplefoc compiles and I flush it to my board, but nothing moves. I use platformio, what could be the problem?\"*. As a recall a good answer here should be to include the `lib_archive=False` information in the platformio.ini file, so we want the retrieval system to extract this information from the docs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvQTC7pp9o4j",
        "colab": {
          "resources": {
            "http://localhost:8080/extras/Images/platformio_screenshot4.png": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/extras/Images/platformio_screenshot5.png": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/extras/Images/platformio_screenshot6.png": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/extras/Images/platformio_screenshot7.png": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/extras/Images/platformio_screenshot1.png": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/extras/Images/platformio_screenshot2.png": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/extras/Images/platformio_screenshot3.png": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "684068ae-6a26-43ef-c8e2-a10619fd01b3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Retrieved Chunk 1 (source 0.76) \n 4. Click finish\n\nAt this point, if it is the first project you are creating for this board, PlatformIO will download all the required compilers, tools and core library files. Depending on your internet speed, this can take quite a few minutes, so please be patient!\n\n## Add <span class=\"simple\">Simple<span class=\"foc\">FOC</span>library</span> to your project\n\nWhen everything is finished installing, you should be presented with a view like this:\n\n<img src=\"extras/Images/platformio_screenshot4.png\" class=\"width80\">\n\nYou can now add the SimpleFOC library to the project:\n\n<img src=\"extras/Images/platformio_screenshot5.png\" class=\"width80\">\n1. Click on the PlatformIO icon, and choose \"Libraries\" from the Menu\n2. Enter \"Simple FOC\" in the search\n3. Click on the library\n\n<img src=\"extras/Images/platformio_screenshot6.png\" class=\"width80\">\n1. Click on \"Add Library\" to display the \"Add Library\" wizard\n\n<img src=\"extras/Images/platformio_screenshot7.png\" class=\"width50\">\n1. Choose your project from the drop-down\n2. Click \"Add\" to add the library\n\nCool! The SimpleFOC library is now associated with your project.\n\n## Configure your project\n\nOpen the platformio.ini file in the root directory of your project. It should look something like this, depending on the board you chose:\n\n```ini\n; PlatformIO Project Configuration File\n;\n;   Build options: build flags, source filter\n;   Upload options: custom upload port, speed and extra flags\n;   Library options: dependencies, extra library storages\n;   Advanced options: extra scripting\n;\n; Please visit documentation for the other options and examples\n; https://docs.platformio.org/page/projectconf.html\n\n[env:mkrwifi1010]\nplatform = atmelsam\nboard = mkrwifi1010\nframework = arduino\nlib_deps = askuric/Simple FOC@^2.2\nlib_archive = false\n```\n\n<blockquote class='warning'>\n<p class='heading'>IMPORTANT! ⚠️</p>\nYou have to add the line <code class='highlighter-rouge'>lib_archive = false</code> to make SimpleFOC compile correctly with PlatformIO."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Retrieved Chunk 2 (source 0.76) \n ⚠️</p>\nYou have to add the line <code class='highlighter-rouge'>lib_archive = false</code> to make SimpleFOC compile correctly with PlatformIO.\n</blockquote>\n\nYou may also want to add some other options, like *monitor_speed* to set the serial port speed for debug output.\n\n```ini\nmonitor_speed = 115200\n```\n\nThe available options depend on your board, and we cannot cover them all here, but they are documented in PlatformIO's documentation.\n\n## Code away!\n\nYou can begin to write your code in the *src/main.cpp* file.\n\n## Youtube tutorial by [@owennewo](https://github.com/owennewo)\n\n<iframe class=\"youtube\" src=\"https://www.youtube.com/embed/3B88qCny7Kg\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n\n## Advanced Usage\n\nPlatformIO makes it easy for you to use the source version of the SimpleFOC library. This lets you modify the code, or use the most recent \"dev\" branch version of the library to try out new features before they are officially released.\n\nTo use the source code version of the library, try the following steps:\n\n1. Using your favourite git client, clone the simplefoc library from https://github.com/simplefoc/Arduino-FOC.git\n2. This will create a folder \"Arduino-FOC\" on your file-system, containing the library source code\n3. Go to your PlatformIO project, and inside the project go to the lib folder. You can use your operating system's shell, or the built-in shell in Visual Studio Code.\n4. Inside the lib folder of your project, create a symlink to your Arduino-FOC folder<br/>\nMac/Linux:<br/>\n`% ln -s /path/to/Arduino-FOC`<br/>\nWindows:<br/>\n`% mklink /J Arduino-FOC C:\\path\\to\\Arduino-FOC`\n\nNote: If you had previously added the release version of the library to the project using PlatformIO's library management, you will have to remove this reference from the platformio.ini file"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Retrieved Chunk 3 (source 0.76) \n # Installing <span class=\"simple\">Simple<span class=\"foc\">FOC</span>library</span> with PlatformIO\n\nUsing SimpleFOC from PlatformIO is not hard at all! The following instructions should get you set up and compiling your code in a matter of minutes.\n\n## Quick setup for pros\n\nYou can use SimpleFOC in Arduino projects in PlatformIO. Just add the library via the library manager.\n\n<b>You will need this option in your platformio.ini file:</b>\n```ini\nlib_archive = false\n```\n\n# Detailed instructions\n\n## Prerequisites\n\n- You need an active internet connection throughout this process, until your project is set up.\n- First, install [Visual Studio Code](https://code.visualstudio.com/download)\n- Run Visual Studio Code, and install PlatformIO using the Extensions Manager:\n\n<img src=\"extras/Images/platformio_screenshot1.png\"  class=\"width80\">\n1. Select extension manager\n2. Enter \"PlatformIO\" in the search\n3. Choose PlatformIO extension from the list (should be the first result)\n4. Click install - after a few moments PlatformIO will be installed, you will be prompted to reload Visual Studio Code\n\nCongratulations, you're ready to start your first project!\n\n## Creating a project\n\nTo create a new project that uses SimpleFOC, use the following steps:\n\n<img src=\"extras/Images/platformio_screenshot2.png\" class=\"width80\">\n1. Select the PlatformIO Menu on the left sidebar\n2. Choose Open to open the platformIO home screen\n3. Click \"New Project\"\n\nYou will be taken to the new project wizard:\n\n<img src=\"extras/Images/platformio_screenshot3.png\" class=\"width50\">\n1. Give your project a name, e.g. simplefoc_test_project\n2. Choose your board. SimpleFOC supports many MCU architectures, see [hardware/mcus]\n3. Once you have chosen your board, make sure the Framework \"Arduino\" is selected. PlatformIO supports other Frameworks, but SimpleFOC is an Arduino Library and must be run in Arduino framework.\n4. Click finish\n\nAt this point, if it is the first project you are creating for this board, PlatformIO will download all the required compilers, tools and core library files."
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "question = \"Simplefoc compiles and I flush it to my board, but nothing moves. I use platformio, what could be the problem?\"\n",
        "response = query_engine.query(question)\n",
        "\n",
        "for i in range(similarity_top_k):\n",
        "    display(Markdown(f\"# Retrieved Chunk {i+1} (source {response.source_nodes[i].score:.2f}) \\n {response.source_nodes[i].text}\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👉 We can see that here RAG did a pretty good job at retrieving relevant information and in fact the instruction to set `lib_archive = false` is present in all 3 retrived chunks, so the LLM should be able to incorporate this in its answer if everything goes well."
      ],
      "metadata": {
        "id": "5AdDs0ddDTY6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHkYZNQ7E6V2"
      },
      "source": [
        "### 5) Import the LLM\n",
        "\n",
        "Choosing the right LLM can be hard, but we are usually quite constrained in our choices depending on the GPUs hardware that we have at our disposal.\n",
        "Here I'm simply using a colab free-access which has 16GB of RAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4w8s0Ktbkshv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f072ec-b231-4f83-c2ff-edc1ee27e1fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available GPU memory: 15 GB\n"
          ]
        }
      ],
      "source": [
        "# Get GPU available memory\n",
        "import torch\n",
        "gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory\n",
        "gpu_memory_gb = round(gpu_memory_bytes / (2**30))\n",
        "print(f\"Available GPU memory: {gpu_memory_gb} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9rkkay9IiiR"
      },
      "source": [
        "Given 16GB of memory is relatively small we have to stick with small and likely *quantized* models. There are different types of quantization methods and one of them is known as **GPTQ**, a post-training quantization (PTQ) method that enable to compress all the weights of these models to a **4-bit precision** that can efficiently run on GPUs.\n",
        "You can find many of these quantized models into the HF Hub, in particular you can check collections from [The Bloke AI](https://huggingface.co/TheBloke) which for instance contains [Llama-2-7B-Chat-GPTQ](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GPTQ), [Mistral-7B-Instruct-v0.2-GPTQ](https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GPTQ) and [zephyr-7B-beta-GPTQ](https://huggingface.co/TheBloke/zephyr-7B-beta-GPTQ).\n",
        "👉 For a deeper dive into GPTQ you can check out [this blog](https://towardsdatascience.com/4-bit-quantization-with-gptq-36b0f4f02c34)\n",
        "\n",
        "\n",
        "Let's import **Mistral-7B-Instruct-v0.2-GPTQ** with its corresponding tokenizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ippPjW9k4Fm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dad94dcc-e2f2-4149-df7d-bf10f180db3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4193: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MistralForCausalLM(\n",
              "  (model): MistralModel(\n",
              "    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x MistralDecoderLayer(\n",
              "        (self_attn): MistralSdpaAttention(\n",
              "          (rotary_emb): MistralRotaryEmbedding()\n",
              "          (k_proj): QuantLinear()\n",
              "          (o_proj): QuantLinear()\n",
              "          (q_proj): QuantLinear()\n",
              "          (v_proj): QuantLinear()\n",
              "        )\n",
              "        (mlp): MistralMLP(\n",
              "          (act_fn): SiLU()\n",
              "          (down_proj): QuantLinear()\n",
              "          (gate_proj): QuantLinear()\n",
              "          (up_proj): QuantLinear()\n",
              "        )\n",
              "        (input_layernorm): MistralRMSNorm()\n",
              "        (post_attention_layernorm): MistralRMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): MistralRMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# load fine-tuned model from hub\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from auto_gptq import exllama_set_max_input_length\n",
        "\n",
        "model_name = \"TheBloke/Mistral-7B-Instruct-v0.2-GPTQ\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
        "                                             device_map=\"auto\",\n",
        "                                             trust_remote_code=False,\n",
        "                                             revision=\"main\")\n",
        "model = exllama_set_max_input_length(model, 8192)\n",
        "\n",
        "# load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "\n",
        "\n",
        "# put the model in eval mode as we are only gonna use it for inference\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7Q6Ytz3Q8Wf"
      },
      "source": [
        "Let's print some model statistics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9Ev3ZPkQ-WU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ce70f1-a084-4fc2-c6ed-0c000b398fe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model has 262410240 parameters\n",
            "Model memory (GB): 4.3729400634765625\n"
          ]
        }
      ],
      "source": [
        "# Get model number of parameters\n",
        "print(f\"Model has {sum([param.numel() for param in model.parameters()])} parameters\")\n",
        "\n",
        "# Get model parameters and buffer sizes\n",
        "mem_params = sum([param.nelement() * param.element_size() for param in model.parameters()])\n",
        "mem_buffers = sum([buf.nelement() * buf.element_size() for buf in model.buffers()])\n",
        "\n",
        "# Calculate model sizes\n",
        "model_mem_bytes = mem_params + mem_buffers\n",
        "model_mem_gb = model_mem_bytes / (1024**3)\n",
        "\n",
        "print(f\"Model memory (GB): {model_mem_gb}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_fm_R_gE6O6"
      },
      "source": [
        "### 6) Augment Input Prompt\n",
        "\n",
        "Now we need to do a bit of prompt-engineering work to decide what we will send as input to the LLM. In this notebook, we'll be using a quantized version of Mistral7B-Instruct. To effectively prompt the Mistral 7B Instruct and get optimal outputs, it's recommended to use the following chat template:\n",
        "\n",
        "```<s>[INST] Instruction [/INST] Model answer</s>[INST] Follow-up instruction [/INST]```\n",
        "\n",
        "`<s>` and `</s>` are special tokens indicating beginning of string (BOS) and end of string (EOS), while `[INST]` and `[/INST]` are regular strings used to delimitate the instruction/query. We can apply this template by hand, or use the `apply_chat_emplate` method from the transformers package which is what is done here.\n",
        "\n",
        "Now a main question here is how to augment the prompt with the retrived chunks such that the LLM can use them most effectively. There are many different tricks to do proper prompt-engineering, most of them being referenced on [this prompting guide](https://www.promptingguide.ai/) but what I did here is simply use the [together.ai](https://api.together.xyz/signin) API to try different prompts \"by hand\" and select the one I was most happy with (`base_prompt` as shown in below cell). As you can see I basically insisted to use the information from the retrieved chunks (and even solely this information) because I felt that that generic LLMs such as Mistral-instruct tend to provide generic answers which is not what we are looking for here. To do so I added a minimal chain-of-thought (CoT) prompting by asking the model to extract relevant information from the provided context items and to reformulate their content in a clear, accessible and consise manner. I also ask the LLM to not mention these context items (because the RAG pipeline would ultimately be hidden to the user) and to directly refer to the online docs. Finally I ask the LLM to sign with \"SimpleFOC_AI\" so that users know that the answer is generated by an AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1V0DEXNCh8z"
      },
      "outputs": [],
      "source": [
        "def create_prompt(query, context_items):\n",
        "    context = \"\"\n",
        "    for i, context_item in enumerate(context_items):\n",
        "        context += f\"# Context item {i+1} \\n {context_item} \\n\\n\"\n",
        "\n",
        "    base_prompt = \"\"\"You are SimpleFOC_AI, a virtual assistant that answer user queries on the SimpleFOC forum.\n",
        "    To do so, you extract relevant information from the SimpleFOC documentation context items provided below, and reformulate their content in a clear and accessible manner. \\\n",
        "    Your answer is as concise and explanatory as possible, and based solely on the information provided in the context items.\n",
        "    Keep in mind that the user does not know about this context so your answer cannot mention these \"items\".\n",
        "    Finally your answer should start with the \"SimpleFOC_AI\" signature and refer to the SimpleFOC documentation (https://docs.simplefoc.com/)  when needed.\n",
        "\n",
        "    \\n\\n{context}\n",
        "\n",
        "    \\n\\nUser query: {query}\n",
        "\"\"\"\n",
        "\n",
        "    base_prompt = base_prompt.format(context=context,\n",
        "                                     query=query)\n",
        "\n",
        "    # Create prompt template for instruction-tuned model\n",
        "    dialogue_template = [\n",
        "        {\"role\": \"user\",\n",
        "         \"content\": base_prompt}\n",
        "    ]\n",
        "\n",
        "    # Apply the chat template\n",
        "    prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
        "                                           tokenize=False,\n",
        "                                           add_generation_prompt=True)\n",
        "\n",
        "    return prompt\n",
        "\n",
        "# Format our prompt\n",
        "prompt = create_prompt(query=question,\n",
        "                          context_items=[response.source_nodes[i].text for i in range(similarity_top_k)])\n",
        "# display(Markdown(prompt[3:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-nKuvQQZQQV"
      },
      "source": [
        "Great, we are now ready to pass our augmented prompt to the LLM and see what it returns. Note that there are few important parameters that we can tune here for generating an answer with the LLM, in particular:\n",
        "\n",
        "* do_sample: enable sampling-based decoding strategies and there are many of them such as\n",
        "    * Multinomial sampling: randomly selects the next token based on the probability distribution over the entire vocabulary, and this is what we use here by default (instead of greedily selecting the one with max predicted probability)\n",
        "    * Top-k sampling (select only a portion of the top-k logits before applying softmax to gain compute efficiency)\n",
        "    * Top-p sampling (given the softmax-predicted probabilities only consider the most likely tokens whose cummulated probabilities > p)\n",
        "    * I recommend [this blogpost](https://huyenchip.com/2024/01/16/sampling) for more information on sampling strategies\n",
        "* temperature: parameters that is used to scale the logits (outputs of the LLM) before they are fed to softmax sampling such that a temperature of 0 will result in deterministic outputs (softmax+$\\tau=0$ <=> hard max) and a higher temperature will result in more diverse/creative outputs. We generally consider $0<\\tau<1$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WkVeMz8Q-wf",
        "outputId": "7d4d410b-edc6-4f06-b3c6-5df33ee25fa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " SimpleFOC_AI: I'm sorry to hear that you're experiencing issues with SimpleFOC not moving your motor after compiling and flashing through PlatformIO. Here are a few suggestions to help you troubleshoot the problem:\n",
            "\n",
            "1. Check your wiring: Make sure all your motor connections are correct and properly connected to the board. Double-check the motor polarities, ground, and power connections.\n",
            "\n",
            "2. Verify your motor configuration: Review the SimpleFOC library documentation (<https://docs.simplefoc.com/>) and ensure that the motor configuration in your code matches your motor setup. The library supports various motor types and configurations, so it's essential to choose the correct one.\n",
            "\n",
            "3. Check your motor parameters: In your code, the SimpleFOC library requires specific motor parameters, such as motor type, RPM, phase resistances, and inductances. Ensure all these parameters are correctly set for your motor.\n",
            "\n",
            "4. Debugging: Use the Serial Monitor in Visual Studio Code (or another terminal) to check for any error messages or issues in your code. You can also add debug statements to your code to inspect variables or motor states.\n",
            "\n",
            "5. Firmware version: Ensure you are using the latest SimpleFOC library version that supports your motor and board. Sometimes compatibility issues can cause problems. You can check for the latest library release on GitHub (<https://github.com/simplefoc/Arduino-FOC/releases>).\n",
            "\n",
            "6. PlatformIO configuration: Double-check your platformio.ini file for any misconfigurations or missing settings. Ensure the 'lib_archive' option is set to 'false' as required for SimpleFOC.\n",
            "\n",
            "7. Hardware issues: If all the above steps do not help, consider checking your hardware for any defects. Try using a different motor or board to rule out any hardware-related issues.\n",
            "\n",
            "If you still cannot find a solution, you can reach out to the SimpleFOC community for help on their official forum (<https://discourse.simplefoc.com/>) or contact the SimpleFOC team for further assistance.\n"
          ]
        }
      ],
      "source": [
        "# we have to reduce the prompt has this dont fit into context\n",
        "prompt = create_prompt(query=question,\n",
        "                          context_items=[response.source_nodes[i].text for i in range(3)])\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"),\n",
        "                         temperature=0.7,\n",
        "                         do_sample=True,\n",
        "                         max_new_tokens=512)\n",
        "\n",
        "print(tokenizer.batch_decode(outputs)[0][len(\"<s> \"+prompt):-len(\"</s>\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBzyKV3V5xty"
      },
      "source": [
        "Cool, there is the desired information (check `lib_archive=false` option in the `platform.ini` file) and the answer is correct and useful 😀\n",
        "\n",
        "However there are still room for improvement: the important information appears quite late in the answer (point 6) and when we do several samples the answer is not alway as good..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQRlG9-cTFHe"
      },
      "source": [
        "## Evaluation 🤔\n",
        "\n",
        "We are now ready to test our RAG pipeline + LLM on a test set of user queries to see how good of a SimpleFOC AI Assistant we've made...\n",
        "\n",
        "For each query, we'll pass it three times (`n_samples=3`) to the LLM to the generated outputs."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = 3"
      ],
      "metadata": {
        "id": "MDfzllnIqoBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0F3w7wugsy6"
      },
      "source": [
        "### Test 1\n",
        "\n",
        "We are first testing whether our RAG pipeline can retrive the info from [this section](https://docs.simplefoc.com/microcontrollers#choosing-the-microcontroller) (first table).\n",
        "\n",
        "The answers should be the following:\n",
        "\n",
        "* \"Is arduino Uno able to produce 6pwm signals with simplefoc?\" -> should say YES  \n",
        "* \"Can esp8266 chip be used to drive 6pwm drivers with simplefoc?\" -> should say  NO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfUg8CNpGSO8"
      },
      "outputs": [],
      "source": [
        "questions = [\"Is arduino Uno able to produce 6pwm signals with simplefoc?\",\n",
        "          \"Can esp8266 chip be used to drive 6pwm drivers with simplefoc?\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdtTeDQQxAHj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "604ecad1-e760-4149-b760-7e480b4887cd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## User Question: Is arduino Uno able to produce 6pwm signals with simplefoc?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: I'm here to help answer your SimpleFOC-related queries using information from the official documentation. Based on the context you've provided, Arduino Uno has only 4 PWM pins, which is not enough to implement a 6-phase motor control. Therefore, it's not possible to generate 6 PWM signals for motor control with SimpleFOC on an Arduino Uno.\n\nFor more details on the specifications of various development boards, you can refer to the documentation or the table you've shared. If you have any other questions about SimpleFOC or its usage, feel free to ask!"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 1"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: I'm SimpleFOC_AI, your helpful assistant from the SimpleFOC documentation.\n\nRegarding your query, the Arduino Uno board has only 4 PWM pins, which is not sufficient for a 6-phase motor control setup. Therefore, it is not possible to implement 6PWM motor control using the SimpleFOC library on an Arduino Uno.\n\nHowever, you can still use the Arduino Uno with SimpleFOC for motor control applications with less than 6 phases, or you can explore alternative hardware options with more PWM channels if you need a 6-phase motor setup.\n\nFor more information about SimpleFOC and its compatibility with different boards, please refer to the [SimpleFOC documentation](https://docs.simplefoc.com/)."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 2"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: I'm SimpleFOC_AI, your helpful assistant for SimpleFOC-related queries. Based on the provided context, an Arduino Uno can use hardware interrupts for encoder setup with SimpleFOC library. However, it only has 4 PWM pins, which is not enough to implement a 6-phase motor control. Therefore, Arduino Uno cannot produce 6 PWM signals for motor control using SimpleFOC directly.\n\nFor more information, I encourage you to explore the SimpleFOC documentation at <https://docs.simplefoc.com/>. If you have any other questions, feel free to ask!"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## User Question: Can esp8266 chip be used to drive 6pwm drivers with simplefoc?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: I'm here to help answer any SimpleFOC-related queries based on the available documentation. The context provided indicates that ESP8266 chips come with only 4 PWM pins and one analog input. Based on SimpleFOC library requirements, the 6PWM motor control and FOC current control cannot be implemented on ESP8266 chips due to this limitation. However, ESP32 chips, which have more PWM pins and are also supported by SimpleFOC, are recommended for driving 6PWM drivers with the library. For more information, visit the SimpleFOC documentation at <https://docs.simplefoc.com/>."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 1"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: I'm here to help answer any queries you have regarding the SimpleFOC library. Based on the information provided, ESP8266 chips do not fully meet the requirements for using 6PWM motor control with SimpleFOC. These chips have only 4 PWM pins, which limits the number of channels that can be used for motor control. Additionally, they only have one analog input, making current control not possible.\n\nIf you need more information about SimpleFOC or require assistance with a specific issue, please refer to the SimpleFOC documentation available at <https://docs.simplefoc.com/>. For ESP32 chips, they support MCPWM interface and can handle two 6PWM drivers, but each pin can be used in PWM mode, as long as you avoid using pins with predefined states on boot.\n\nPlease note that the support for ESP8266 chips in SimpleFOC is still in the initial stages and may have some limitations. However, you can always consider using other boards that meet the full requirements for 6PWM motor control with SimpleFOC, such as the ESP32 boards mentioned above."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 2"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: I'm here to help answer your query regarding using an ESP8266 chip with SimpleFOC for 6PWM driver control.\n\nAccording to the information available in the SimpleFOC documentation, ESP8266 chips have only 4 PWM pins, whereas the 6PWM motor control and FOC current control both require more PWM pins than that. Therefore, ESP8266 chips are not currently supported for 6PWM driver control using SimpleFOC.\n\nFor more information on SimpleFOC, please refer to the official documentation at <https://docs.simplefoc.com/>. If you have any other questions, feel free to ask!"
          },
          "metadata": {}
        }
      ],
      "source": [
        "for question in questions:\n",
        "\n",
        "    response = query_engine.query(question)\n",
        "\n",
        "    prompt = create_prompt(query=question,\n",
        "                            context_items=[response.source_nodes[i].text for i in range(3)])\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    display(Markdown(f\"## User Question: {question}\"))\n",
        "    for sample_idx in range(n_samples):\n",
        "        outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"),\n",
        "                                temperature=0.7,\n",
        "                                do_sample=True,\n",
        "                                max_new_tokens=1024)\n",
        "        display(Markdown(f\"### Output {sample_idx}\"))\n",
        "        display(Markdown(tokenizer.batch_decode(outputs)[0][len(\"<s> \"+prompt):-len(\"</s>\")]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👉 For the first question, unfortunately all outputs are incorrect hallucinations 😓 Indeed they all suggest thar Arduino UNO is not able to produce 6pwm signals with SimpleFOC, whereas it actually is. Looking at the RAG retrieved items for this query, we see that it retrived a chunk coming from [this part](https://docs.simplefoc.com/esp_mcu#esp8266-boards-support) of the documentation about ESP8266 which says that \"These boards have only 4 pwm pins so the 6PWM motor control cannot be implemented\" and cutting the previous info that this is ESP8266 and not Arduino UNO, which is likely the cause of hallucinations here.\n",
        "\n",
        "\n",
        "👉 For the second question however the generated answers are very good, providing correct information and refering to the docs for additional information which is great (and better to what we got with chatGPT at the beginning)."
      ],
      "metadata": {
        "id": "-f8IAJ4TSCYc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJlIrRUqXY4c"
      },
      "source": [
        "### Test 2\n",
        "\n",
        "We are also testing whether our RAG pipeline can retrive info from the third table from the same section.\n",
        "\n",
        "The answers should be the following:\n",
        "\n",
        "* \"Does simplefoc implement low-side current sensing for stm32 microcontroller l4 family?\" --> should say YES\n",
        "* \"Does simplefoc implement low-side current sensing for stm32 microcontroller h7 family?\" --> should say YES\n",
        "* \"Does simplefoc implement low-side current sensing for teensy microcontrollers?\" --> should say NO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7mTlnr4XY4d"
      },
      "outputs": [],
      "source": [
        "questions = [\"Does simplefoc implement low-side current sensing for stm32 microcontroller l4 family?\",\n",
        "             \"Does simplefoc implement low-side current sensing for stm32 microcontroller h7 family?\",\n",
        "             \"Does simplefoc implement low-side current sensing for teensy microcontrollers?\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sX1zGBHXXY4e",
        "outputId": "831cce09-7b5b-4a34-d68f-c71ba92906df"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## User Question: Does simplefoc implement low-side current sensing for stm32 microcontroller l4 family?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: The SimpleFOC library currently supports low-side current sensing on certain members of the STM32 microcontroller family, specifically the f1, f4, and g4 families. Unfortunately, the l4 family is not mentioned in the documentation. Therefore, I cannot confirm whether it is supported or not with certainty. For the most accurate and up-to-date information, please refer to the SimpleFOC documentation at <https://docs.simplefoc.com/>."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 1"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC\\_AI: I'm here to help answer queries related to the SimpleFOC library. Based on the provided context, the current sensing support for the STM32 microcontroller family includes STM32f1, STM32f4, and STM32g4, which all support low-side current sensing for one motor. However, I cannot confirm if the STM32 L4 family is currently supported for low-side current sensing in SimpleFOC. For the most accurate and up-to-date information, you should refer to the SimpleFOC documentation available at <https://docs.simplefoc.com/>."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 2"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: The SimpleFOC library currently supports low-side current sensing for some STM32 microcontroller families like f1, f4, and g4. However, I cannot confirm if it specifically supports the L4 family at this moment. I recommend checking the latest documentation on the SimpleFOC website (<https://docs.simplefoc.com/>) for the most accurate information regarding the specific STM3 microcontroller family L4."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## User Question: Does simplefoc implement low-side current sensing for stm32 microcontroller h7 family?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: The SimpleFOC library supports low-side current sensing for some STM32 microcontroller families, including the STM32 H7. However, it's essential to note that the current sensing functionality is limited to one motor for this microcontroller family. For more information about the supported MCUs and their current sensing capabilities, please refer to the SimpleFOC documentation on https://docs.simplefoc.com/."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 1"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: I'm glad you're interested in SimpleFOC's current sensing capabilities with the STM32 H7 microcontroller family. According to the SimpleFOC documentation, low-side current sensing is supported for the STM32 H7 family, specifically on the B-G431B-ESC1 board. However, the documentation also states that the SAMD21 architecture is under development and its low-side current sensing implementation is not yet fully tested, so I would recommend exercising caution when relying on it.\n\nSince you've asked about low-side current sensing specifically for the STM32 H7 family, I'd like to clarify that this architecture supports one motor with low-side current sensing. Keep in mind that low-side current sensing requires a very high synchronization between the PWM generated by the driver and the ADC triggering, so it's important to consider the PWM frequency and the PWM pins when choosing the driver parameters.\n\nFor more information, you can refer to the SimpleFOC documentation on current sensing (<https://docs.simplefoc.com/current-sensing/>) and the MCU support page (<https://docs.simplefoc.com/MCU-support/>)."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 2"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: The SimpleFOC library currently supports low-side current sensing for the STM32 microcontroller families f1, f4, and g4, but not for H7. You can refer to the SimpleFOC documentation at <https://docs.simplefoc.com/> for more detailed information on the currently supported MCUs and current sensing methods."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## User Question: Does simplefoc implement low-side current sensing for teensy microcontrollers?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC\\_AI: I'm glad you're interested in SimpleFOC and its current sensing capabilities. Based on the information available in the provided context items, SimpleFOC currently does not support low-side current sensing for Teensy microcontrollers. If you have any other questions about SimpleFOC or its features, feel free to ask! For more details on SimpleFOC and its current sensing approaches, please refer to the official documentation at <https://docs.simplefoc.com/>."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 1"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: I'm glad you're interested in current sensing options with SimpleFOC! Based on the provided context, I see that low-side current sensing is supported on several microcontroller units (MCUs), but unfortunately, Teensy microcontrollers are not currently among them. I recommend checking the SimpleFOC documentation for the latest supported MCUs and their respective current sensing options at <https://docs.simplefoc.com/>."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 2"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: I'm glad you're interested in using the SimpleFOC library for your Teensy microcontroller project. Regarding your question, the current version of SimpleFOC does not support low-side current sensing for Teensy microcontrollers. The library currently supports in-line current sensing for this platform. However, the development team aims to make SimpleFOC as interchangeable as possible across different drivers and platforms, so new features and improvements, including low-side current sensing for Teensy, may be added in future releases. Be sure to check the SimpleFOC documentation at <https://docs.simplefoc.com/> for the latest information."
          },
          "metadata": {}
        }
      ],
      "source": [
        "for question in questions:\n",
        "\n",
        "    response = query_engine.query(question)\n",
        "\n",
        "    prompt = create_prompt(query=question,\n",
        "                            context_items=[response.source_nodes[i].text for i in range(3)])\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    display(Markdown(f\"## User Question: {question}\"))\n",
        "    for sample_idx in range(n_samples):\n",
        "        outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"),\n",
        "                                temperature=0.7,\n",
        "                                do_sample=True,\n",
        "                                max_new_tokens=1024)\n",
        "        display(Markdown(f\"### Output {sample_idx}\"))\n",
        "        display(Markdown(tokenizer.batch_decode(outputs)[0][len(\"<s> \"+prompt):-len(\"</s>\")]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👉 For the question about low-side sensing support for the stm32 l4 family, the answers does not convey confidently that they support low-side sensing (which is the case), but what I like is that they neither convey the feeling that they don't support it but rather that the AI assistant is uncertain about this query, and that user should check the SimpleFOC website for more accurate informationn which is much better than hallucinating false information. Actually here when we look at the retrieved information from the docs, we understand why the LLM is uncertain as the information is not so clearly explained in the docs. For instance it is emphasized that Stm32 f1, f4 and g4 families support low-side sensing for only one motor which looks like it *implicitely* suggests that Stm32 l4 family does not support low-side support in contrast, whether what it actually suggests is that l4 family support it for more than one motor as well. Maybe this tool could actually be useful to write better docs 😆\n",
        "\n",
        "👉 For the same question about stm32 h7 family, there are 2 out of 3 answers that are correct with the last one being the incorrect one. But its not so bad as once again the information is not clearly stated in the docs, for instance the h7 family is not included in [this table](https://docs.simplefoc.com/stm32_mcu#stm32-boards-support) which summarizes stm32 support. There is also a problem in the second answer, which wrongly suggests that B-G431B-ESC1 board which however is listed in the table, is from the h7 family, but this is wrong.\n",
        "\n",
        "👉 Finally for the same question about teensy microcontrollers, all 3 answers are correct and concise, referring to the SimpleFOC docs which is nice! However they often refer to the \"provided context\" or even \"context items\" despite me asking explicitely referring in the base prompt to not refer to those (as these would be hidden to the user), so there is probably some further improvements to make to the base prompt!"
      ],
      "metadata": {
        "id": "AJvNTJCHWHwU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1aM0a3yeGPt"
      },
      "source": [
        "### Test 3\n",
        "\n",
        "We are again testing information contained within the same page in the docs, but answering it requires a bit more of context as the user is asking for advice between several configurations, and the LLM should reason and compare the different options based on the info provided in the docs. Moreover there is various terms that the LLM should know about e.g. \"nucleo f411re\" is a specific nucleo board from the stm32 microcontroller f4 family.\n",
        "\n",
        "The answers should be the following:\n",
        "\n",
        "* \"If I have a choice between Arduino UNO, esp32 and stm32f1 chip, which one should I use if I wanna run 2 bldc motors with simplefoc with encoders and low-side current sensing?\" --> should say esp32\n",
        "* \"If I have a choice between Arduino UNO and nucleo f411re, which one is a better choice for smooth motor control with simplefoc? \" --> should say nucleo f411re (equivalent to stm32 f4 family)\n",
        "* \"If I have a choice between teensy 4.0 and stm32f1 and a 6pwm driver, which one should I use with simplefoc?\" --> should say teensy 4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiqsftrIeGPu"
      },
      "outputs": [],
      "source": [
        "questions = [\"If I have a choice between Arduino UNO, esp32 and stm32f1 chip, which one should I use if I wanna run 2 bldc motors with simplefoc with encoders and low-side current sensing?\",\n",
        "             \"If I have a choice between Arduino UNO and nucleo f411re, which one is a better choice for smooth motor control with simplefoc?\",\n",
        "             \"If I have a choice between teensy 4.0 and stm32f1 and a 6pwm driver, which one should I use with simplefoc?\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lpTv0Z4neGPu",
        "outputId": "8f1c8666-b818-4da3-8fc8-c9232b7c5c05"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## User Question: If I have a choice between Arduino UNO, esp32 and stm32f1 chip, which one should I use if I wanna run 2 bldc motors with simplefoc with encoders and low-side current sensing?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: Based on your requirements of running two BLDC motors with encoders and low-side current sensing using the SimpleFOC library, I would recommend considering an STM32F1 family chip. The STM32F1 series provides initial support for low-side current sensing for one motor, and they offer a good balance of power and flexibility for your project.\n\nHere's a brief summary of the options you have:\n\n1. Arduino UNO: This microcontroller does not support low-side current sensing, so it's not recommended for your specific use case.\n2. ESP32: ESP32 devices are capable of running 4 BLDC motors with FOC algorithm. However, due to their communication capabilities, they might have some issues with precise real-time control. Low-side current sensing is supported, but it's limited to one motor.\n3. STM32F1: The initial support for low-side current sensing for one motor makes STM32F1 a good choice. It offers a balance between power and flexibility, and it's widely used in the community for FOC projects.\n\nFor more detailed information, please refer to the SimpleFOC library documentation at <https://docs.simplefoc.com/>."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 1"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: Based on your requirements of running two BLDC motors with encoders and low-side current sensing using the SimpleFOC library, the STM32F1 family would be a suitable choice. The STM32F1 series supports low-side current sensing for one motor, and it has a good number of external interrupt pins, which can be used for encoder signals and PWM outputs. Additionally, the STM32F1 series has low loop times, making the FOC algorithm smoother. However, please note that programming the STM32F1 series might be more complex compared to Arduino UNO or ESP32, but with the SimpleFOC library integrated into the Arduino IDE, this is not a significant issue. Regards, SimpleFOC_AI. (SimpleFOC documentation: <https://docs.simplefoc.com/>)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 2"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: Based on your requirements of running two BLDC motors with encoders and low-side current sensing using the SimpleFOC library, the best option among Arduino UNO, esp32, and stm32f1 would be the stm32f1 chip. This is because, as stated in the SimpleFOC documentation, stm32f1 devices support low-side current sensing for one motor. Additionally, they have a sufficient number of external interrupt pins to accommodate the encoder signals and motor control PWM signals for both motors.\n\nHowever, keep in mind that the Arduino SimpleFOC library code for stm32 devices is the same as for Arduino UNO, except for the pin numbers. Furthermore, stm33 devices provide much better performance and smoother FOC algorithm execution due to their higher processing power, lower loop times, and larger number of external interrupts.\n\nFor more information on current sensing support and hardware considerations, please refer to the SimpleFOC documentation at https://docs.simplefoc.com/."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## User Question: If I have a choice between Arduino UNO and nucleo f411re, which one is a better choice for smooth motor control with simplefoc?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: Based on the provided context, the STM32 Nucleo F411RE is a better choice for smooth motor control using the SimpleFOC library. This is because Nucleo boards have more external interrupt pins, which is essential for handling encoder signals in the FOC algorithm. Additionally, STM32 devices are more powerful and have lower loop times, leading to smoother motor control. However, programming these devices might be more complex compared to Arduino UNO. For more details, check the SimpleFOC documentation on the official website (<https://docs.simplefoc.com/>)."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 1"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: Based on the information available in the SimpleFOC documentation, both Arduino UNO and Nucleo F411RE boards can be used with the SimpleFOC library for smooth motor control. However, there are some differences between the two:\n\n1. Arduino UNO has a limited number of interrupts and might not be the best choice if you plan to use multiple motors or encoders. The Arduino Mega, which also uses the AVR architecture, has more interrupts and might be a better choice in this case.\n2. Nucleo F411RE, which is based on STM32 microcontrollers, is more powerful and has more external interrupt pins. This makes it a better choice for implementing the FOC algorithm, as it results in smoother motor control with lower loop times. It can run up to 4 BLDC motors without a problem and supports various types of position sensors and motor drivers.\n\nTherefore, if you are looking for the smoothest motor control with SimpleFOC, the Nucleo F411RE is the better choice. However, keep in mind that the Arduino IDE now supports programming STM32 devices, making the complexity of programming these devices less of an issue.\n\nFor more information, you can refer to the SimpleFOC documentation at <https://docs.simplefoc.com/>."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 2"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: Based on the documentation, both Arduino UNO and Nucleo F411RE can be used with the SimpleFOC library for motor control. However, there are some differences to consider:\n\n1. Arduino UNO has fewer interrupts, which might limit the number of motors you can control simultaneously. But with two motors, you should be able to achieve good results.\n\n2. Nucleo F411RE, being an STM32 device, offers more processing power, faster loop times, and a larger number of external interrupts. This makes it a better choice for smoother motor control and handling more motors. The library code for STM32 devices is the same as for Arduino UNO, but with different pin numbers.\n\nIn summary, given your choice between Arduino UNO and Nucleo F411RE, the Nucleo F411RE is the better choice for smoother motor control with SimpleFOC due to its faster processing and larger number of external interrupts."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## User Question: If I have a choice between teensy 4.0 and stm32f1 and a 6pwm driver, which one should I use with simplefoc?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: Based on the provided context, both Teensy 4.0 and STM32F1 boards are compatible with SimpleFOC library for 6PWM driver. However, the Teensy 4.0 has more PWM channels (35) compared to STM32F1 (12), which could be a deciding factor depending on your specific use case.\n\nRegarding the Teensy 4.0, it uses an ARM Cortex-M7 processor, which is more powerful than the Cortex-M3 or M4 processors used in most STM32F1 boards. This could potentially result in better performance and capabilities.\n\nAs for STM32F1, it offers current sensing support for in-line and low-side configurations for one motor. If your application requires current sensing, STM32F1 could be a better choice.\n\nIn summary, if you don't require current sensing and prefer more PWM channels and better processing power, Teensy 4.0 could be the better choice. If you need current sensing or prefer a lower-cost, more widely available option, STM32F1 could be more suitable for you.\n\nFor further information, please refer to the SimpleFOC documentation at <https://docs.simplefoc.com>."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 1"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: Based on the information available in the SimpleFOC documentation, both Teensy 4.0 and STM32F1 support 6 PWM modes. However, there are some differences between these microcontrollers.\n\nTeensy 4.0 uses an ARM Cortex-M7 processor, which provides 35 PWMs and runs at 600 MHz. On the other hand, STM32F1, such as the one mentioned in the context item 2, uses an ARM Cortex-M3 or Cortex-M4 processor with 12 PWMs and runs at 72 MHz.\n\nWhen it comes to current sensing, the STM32F1 family supports low-side current sensing for one motor. This might be an important factor depending on your specific application requirements.\n\nIn general, both teensy 4.0 and STM32F1 can run SimpleFOC library. I recommend considering the number of PWMs you need, the available current sensing options, and the processing power required for your application when choosing between Teensy 4.0 and STM32F1.\n\nFor more information, you can refer to the SimpleFOC documentation on teensy (<https://docs.simplefoc.com/en/latest/hardware_compatibility.html#teensy>) and STM32 (<https://docs.simplefoc.com/en/latest/hardware_compatibility.html#stm32>) support."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 2"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: Based on the information available in the SimpleFOC documentation, both Teensy 4.0 and STM32F1 are compatible with the SimpleFOC library in 6PWM mode. However, the Teensy 4.0 supports more PWMs (35 PWMs) compared to STM32F1 (12 PWMs in total). This could be a deciding factor if you plan to control more motors or other components that require PWM control.\n\nAdditionally, the Teensy 4.0 supports both low-side and high-side current sensing out of the box, while STM32F1 supports only in-line current sensing. If you're planning to use current sensing, make sure to check which type suits your application best.\n\nFor further details, I recommend checking the SimpleFOC documentation on the official website (<https://docs.simplefoc.com/>) or posting your question on the SimpleFOC community forum (<https://community.simplefoc.com/>) for more specific advice."
          },
          "metadata": {}
        }
      ],
      "source": [
        "for question in questions:\n",
        "\n",
        "    response = query_engine.query(question)\n",
        "\n",
        "    prompt = create_prompt(query=question,\n",
        "                            context_items=[response.source_nodes[i].text for i in range(3)])\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    display(Markdown(f\"## User Question: {question}\"))\n",
        "    for sample_idx in range(n_samples):\n",
        "        outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"),\n",
        "                                temperature=0.7,\n",
        "                                do_sample=True,\n",
        "                                max_new_tokens=1024)\n",
        "        display(Markdown(f\"### Output {sample_idx}\"))\n",
        "        display(Markdown(tokenizer.batch_decode(outputs)[0][len(\"<s> \"+prompt):-len(\"</s>\")]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👉 UNO vs esp32 vs stm32f1: unfortunately all the answers suggest to use stm32f1 rather than esp32, and it does not understand than esp32 is the only one which can support 2 motors. But again it is not so bad as the information is still correct and it is true that it is not so clear in the docs to understand that esp32 is supporting two motors e.g. in [the 3rd table from this section](https://docs.simplefoc.com/microcontrollers#choosing-the-microcontroller) it is the only line which has a ✅ and that does not say \"one-motor\" but for the LLM to accurately find and interpret this information is very hard.\n",
        "\n",
        "👉 UNO vs nucleo f411re: perfect 3/3 here!\n",
        "\n",
        "👉 teensy vs stm32f1:  2/3 here as the last answer is wrong and even suggests confidently that \"Teensy 4.0 supports both low-side and high-side current sensing out of the box\" which is completely false! Moreover in the second answer there is also a suggestion that \"Teensy 4.0 uses an ARM Cortex-M7 processor, which provides 35 PWMs\" which might be an hallucination (to check) and is anyway irrelevant here as the question asks for 6PWM. It also provides a link to the simplefoc documentation which does not exists. Could be better!"
      ],
      "metadata": {
        "id": "tu_I5IZtbkQc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GBVNGuLeGx5"
      },
      "source": [
        "### Test 4\n",
        "\n",
        "This question is the example we chose at the beginning, which is a commonly raised question by the community when using SimpleFOC library with PlatformIO and for which the relevant docs is accessible here: [https://docs.simplefoc.com/library_platformio](https://docs.simplefoc.com/library_platformio).\n",
        "\n",
        "The answer should be the following:\n",
        "\n",
        "* \"Simplefoc compiles and I flush it to my board, but nothing moves. I use platformio, what could be the problem?\" --> It should suggest to add `lib_archive = false` to the platrofrmio.ini file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAFdxR39eGx6"
      },
      "outputs": [],
      "source": [
        "questions = [\"Simplefoc compiles and I flush it to my board, but nothing moves. I use platformio, what could be the problem?\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Kz3Y5T_3eGx7",
        "outputId": "681f8ae2-c09b-4af2-a011-4a39ad86dbf5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## User Question: Simplefoc compiles and I flush it to my board, but nothing moves. I use platformio, what could be the problem?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: I'm here to help you troubleshoot issues you might have with using SimpleFOC library in PlatformIO. Based on the information you've provided, it seems that your SimpleFOC code is compiling and being uploaded to your board, but the motors are not moving. Here are some possible causes and solutions for this issue:\n\n1. **Check the wiring**: Make sure that the motors are properly connected to the board, and that the motor phases, grounds, and power sources are all wired correctly. You can consult the SimpleFOC documentation to verify the wiring scheme for your motor type.\n\n2. **Check the code**: Ensure that your code is written correctly and that the motor configuration parameters, such as the motor type, direction, and PID gains, are set correctly. You can refer to the SimpleFOC documentation for examples on how to configure and use the library in Arduino projects.\n\n3. **Check the PID gains**: The PID gains control the behavior of the motor control algorithm. If the gains are not set correctly, the motor might not respond as expected. You can consult the SimpleFOC documentation for guidelines on how to tune the PID gains for your specific application.\n\n4. **Check the sensor connection**: Make sure that the sensors (encoder or speed sensor) are connected to the board and to the correct pins. You can refer to the SimpleFOC documentation for the recommended wiring scheme for your sensor type.\n\n5. **Check the PlatformIO configuration**: Ensure that the SimpleFOC library is being included in your project correctly and that the `lib_archive` option is set to `false`. If you are using the source version of the library, you will also need to create a symlink as described in the PlatformIO documentation.\n\n6. **Check the power supply**: Make sure that the power supply to the motors and the board is stable and within the recommended voltage range. Low voltage or voltage spikes can cause the motor to not move or behave erratically.\n\nIf none of the above steps solve the issue, consider providing more details about the project setup, board, and motor configurations, as well as any error messages or debug output, to help narrow down the cause of the problem. Additionally, you may want to consult the SimpleFOC and PlatformIO documentation for more information and troubleshooting tips."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 1"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: I'm here to help you troubleshoot your issue with SimpleFOC not moving your motor using PlatformIO. Based on the context provided, here are some steps you can take to identify and resolve the problem:\n\n1. Check your wiring: Ensure that the motor wiring is correctly connected to the appropriate pins on your board and that you have a proper connection between the motor controller and the MCU.\n\n2. Verify motor direction: Review the configuration of your motor direction in the SimpleFOC library. Make sure that it matches the physical direction of your motor.\n\n3. Review your code: Check that you correctly imported the SimpleFOC library into your project and that you're using the correct functions and parameters.\n\n4. Motor control example: Attempt to run the motor control example provided with SimpleFOC. If the example works correctly, it is likely that there's an issue in your code. If not, it could be an issue with the library, your board, or your setup.\n\n5. Communication between the MCU and motor controller: Make sure that the communication between the MCU and the motor controller is working properly. You can check the serial monitor in PlatformIO to verify if any error messages are being displayed.\n\n6. PlatformIO configuration: Ensure that you've correctly configured your project in the platformio.ini file. Double-check that the board, framework, and library settings are correct.\n\n7. Firmware version: Check that you're using the latest version of both SimpleFOC and PlatformIO. If not, try updating them to their latest releases to see if that resolves the issue.\n\n8. Debugging: Use PlatformIO's debugging capabilities, such as the Serial Monitor, to help you narrow down the problem.\n\nIf none of these steps help, please provide more details about your setup, including the board you're using, the motor controller, and the specific error messages you're encountering. This will help us better understand and assist you with your issue.\n\nAdditionally, you can refer to SimpleFOC's documentation and community resources, including the [SimpleFOC GitHub repository](https://github.com/simplefoc/Arduino-FOC), the [SimpleFOC Discord server](https://discord.gg/v2nX4Yv), and the [SimpleFOC community forum](https://discourse.simplefoc.com/)."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 2"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC\\_AI: I'm sorry to hear that you're having trouble getting your SimpleFOC project to move using PlatformIO. There are a few potential causes for this issue.\n\nFirst, make sure you have correctly configured your project by adding the SimpleFOC library to it and setting the `lib_archive` option to `false` in your `platformio.ini` file. This is necessary for SimpleFOC to compile correctly with PlatformIO.\n\nNext, check your wiring and motor connections. Make sure that the motors are connected to the correct pins and that they have the correct polarity. You can refer to the documentation on the SimpleFOC GitHub page (<https://github.com/simplefoc/Arduino-FOC>) for information on how to connect the motors and sensors.\n\nAnother possibility is that your motor parameters may not be set correctly. You can find the motor configuration examples in the SimpleFOC library under the `examples/MotorConfig` folder. Adjust the motor parameters to match your specific setup.\n\nLastly, ensure that your code is correctly initializing and controlling the motors. Review your code and make sure that you are calling the necessary functions to initialize and control the motors.\n\nIf you are still having trouble, consider reaching out to the SimpleFOC community on the SimpleFOC GitHub page or the PlatformIO forum for further assistance."
          },
          "metadata": {}
        }
      ],
      "source": [
        "for question in questions:\n",
        "\n",
        "    response = query_engine.query(question)\n",
        "\n",
        "    prompt = create_prompt(query=question,\n",
        "                            context_items=[response.source_nodes[i].text for i in range(3)])\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    display(Markdown(f\"## User Question: {question}\"))\n",
        "    for sample_idx in range(n_samples):\n",
        "        outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"),\n",
        "                                temperature=0.7,\n",
        "                                do_sample=True,\n",
        "                                max_new_tokens=1024)\n",
        "        display(Markdown(f\"### Output {sample_idx}\"))\n",
        "        display(Markdown(tokenizer.batch_decode(outputs)[0][len(\"<s> \"+prompt):-len(\"</s>\")]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👉 The answers are very good here, only the second answer remains a bit too long/generic and doest not explicitly mention the `lib_archive=false` option even though it mentions checking the configuration of the platformio.ini file. But in general the answers are very useful!"
      ],
      "metadata": {
        "id": "SLDHvrKRfj8M"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIdRf7epeHXI"
      },
      "source": [
        "### Test 5\n",
        "\n",
        "Finally we test whether RAG pipeline is able to retrieve info correctly from [this section](https://docs.simplefoc.com/position_sensors) of the docs.\n",
        "\n",
        "The answers should be the following:\n",
        "\n",
        "* \"What are the supported position sensors with simplefoc?\" --> should say Encoder, Magnetic sensor and Hall sensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMFXY84LeHXI"
      },
      "outputs": [],
      "source": [
        "questions = [\"What are the supported position sensors with simplefoc?\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "EsIYTMcReHXI",
        "outputId": "829a7fb7-627b-4316-aa45-fb7625dc05db"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## User Question: What are the supported position sensors with simplefoc?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC\\_AI: The SimpleFOC library supports various types of position sensors, including encoders and magnetic sensors. Encoders are the most commonly used position sensors due to their precision, standardization, and low noise level. Magnetic sensors, on the other hand, use precise magnetic field measurement to estimate position. The library also plans to support IMU sensors in the future. (Refer to the SimpleFOC documentation for more details.)\n\nFor encoders, the library supports optical, capacitive, and magnetic types. You can find examples and prices of these encoders on various e-commerce platforms such as eBay or Mouser. Encoder precision and execution efficiency are important factors to consider when selecting an encoder for your application.\n\nEncountering issues during motor initialization can be due to problems with the position sensor or the current sense. Debugging such issues can be facilitated using the SimpleFOCDebug class. This class provides methods like SIMPLEFOC_DEBUG() for logging messages to the console. You can also use FlashStringHelper, disable debug output globally using the build flag SIMPLEFOC_DISABLE_DEBUG, and understand the rationale behind using SimpleFOCDebug instead of Serial.println in the library. (Refer to the SimpleFOC documentation for more information.)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 1"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: The SimpleFOC library supports encoders and magnetic sensors as position sensors. Encoders estimate position by counting impulses on their `A`, `B`, and `index` channels. Magnetic sensors use precise magnetic field measurement to estimate position. For more information, please refer to the SimpleFOC documentation on position sensors at <https://docs.simplefoc.com/>."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 2"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: The SimpleFOC library supports encoders and magnetic sensors as position sensors. Encoders are the most commonly used position sensors due to their precision, standardization, and low noise level. Magnetic sensors, on the other hand, use precise magnetic field measurement to estimate position. For more information, please refer to the SimpleFOC documentation on position sensors at <https://docs.simplefoc.com/position-sensors/>."
          },
          "metadata": {}
        }
      ],
      "source": [
        "for question in questions:\n",
        "\n",
        "    response = query_engine.query(question)\n",
        "\n",
        "    prompt = create_prompt(query=question,\n",
        "                            context_items=[response.source_nodes[i].text for i in range(3)])\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    display(Markdown(f\"## User Question: {question}\"))\n",
        "    for sample_idx in range(n_samples):\n",
        "        outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"),\n",
        "                                temperature=0.7,\n",
        "                                do_sample=True,\n",
        "                                max_new_tokens=1024)\n",
        "        display(Markdown(f\"### Output {sample_idx}\"))\n",
        "        display(Markdown(tokenizer.batch_decode(outputs)[0][len(\"<s> \"+prompt):-len(\"</s>\")]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👉 The answers are generally correct but they only mention encoders and magnetic sensors, and forget bout Hall sensors which is weird because it is retrieved in one of the context items (but it is also absent from other chunks which might explain why the LLM does not mention it). However the first answer (output 0) is too long and everything after the first paragraph is too far away from the user query, outputs 1 and 2 are better."
      ],
      "metadata": {
        "id": "s9YKXq25h_lx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBvOP0t_eHi9"
      },
      "source": [
        "### Test 6\n",
        "\n",
        "Finally we test if the RAG pipeline is able to help users debug their SimpleFOC code.\n",
        "\n",
        "Here is the question:\n",
        "\"My code does not work, what could be the problem?\n",
        "\n",
        "```cpp\n",
        "#include <SimpleFOC.h>\n",
        "\n",
        "Encoder encoder = Encoder(2, 3, 500);\n",
        "// interrupt routine initialisation\n",
        "void doA(){encoder.handleA();}\n",
        "void doB(){encoder.handleB();}\n",
        "\n",
        "void setup() {\n",
        "  // monitoring port\n",
        "  Serial.begin(115200);\n",
        "  \n",
        "  // initialise encoder hardware\n",
        "  sensor.init();\n",
        "  // hardware interrupt enable\n",
        "  encoder.enableInterrupts(doA, doB);\n",
        "\n",
        "  Serial.println(\"Encoder ready\");\n",
        "  _delay(1000);\n",
        "}\n",
        "\n",
        "void loop() {\n",
        "  // display the angle and the angular velocity to the terminal\n",
        "  Serial.print(sensor.getAngle());\n",
        "  Serial.print(\"\\t\");\n",
        "  Serial.println(sensor.getVelocity());\n",
        "}\n",
        "```\n",
        "\n",
        "The answers should be to include the following in the loop\n",
        "\n",
        "```cpp\n",
        " // IMPORTANT\n",
        "  // read sensor and update the internal variables\n",
        "  sensor.update();\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLmKI1xqeHi-"
      },
      "outputs": [],
      "source": [
        "questions = [\"\"\"my code does not work, what could be the problem?\n",
        "```cpp\n",
        "#include <SimpleFOC.h>\n",
        "\n",
        "Encoder encoder = Encoder(2, 3, 500);\n",
        "// interrupt routine initialisation\n",
        "void doA(){encoder.handleA();}\n",
        "void doB(){encoder.handleB();}\n",
        "\n",
        "void setup() {\n",
        "  // monitoring port\n",
        "  Serial.begin(115200);\n",
        "\n",
        "  // initialise encoder hardware\n",
        "  sensor.init();\n",
        "  // hardware interrupt enable\n",
        "  encoder.enableInterrupts(doA, doB);\n",
        "\n",
        "  Serial.println(\"Encoder ready\");\n",
        "  _delay(1000);\n",
        "}\n",
        "\n",
        "void loop() {\n",
        "  // display the angle and the angular velocity to the terminal\n",
        "  Serial.print(sensor.getAngle());\n",
        "  Serial.print(\"\\t\");\n",
        "  Serial.println(sensor.getVelocity());\n",
        "}\n",
        "```\n",
        "\"\"\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tFWnRvH_eHi_",
        "outputId": "281f73c9-6eae-4f99-d4b0-24f117340cdf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## User Question: my code does not work, what could be the problem?\n```cpp\n#include <SimpleFOC.h>\n\nEncoder encoder = Encoder(2, 3, 500);\n// interrupt routine initialisation\nvoid doA(){encoder.handleA();}\nvoid doB(){encoder.handleB();}\n\nvoid setup() {\n  // monitoring port\n  Serial.begin(115200);\n\n  // initialise encoder hardware\n  sensor.init();\n  // hardware interrupt enable\n  encoder.enableInterrupts(doA, doB);\n\n  Serial.println(\"Encoder ready\");\n  _delay(1000);\n}\n\nvoid loop() {\n  // display the angle and the angular velocity to the terminal\n  Serial.print(sensor.getAngle());\n  Serial.print(\"\t\");\n  Serial.println(sensor.getVelocity());\n}\n```\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: Based on the code you've provided, it seems that there are a few issues. Firstly, you have a typo in your variable name for the encoder. It should be named `encoder` instead of `sensor`. Also, you need to initialize the software interrupt library and attach the listeners to the correct encoder pins. Here is the corrected code:\n\n```cpp\n#include <SimpleFOC.h>\n#include <PciManager.h>\n#include <PciListenerImp.h>\n\n// define Encoder\nEncoder encoder = Encoder(2, 3, 500);\n\n// channel A and B callbacks\nvoid doA(){encoder.handleA();}\nvoid doB(){encoder.handleB();}\n\n// pin change listeners\nPciListenerImp listenerA(encoder.pinA, doA);\nPciListenerImp listenerB(encoder.pinB, doB);\n\nvoid setup() {\n  // monitoring port\n  Serial.begin(115200);\n\n  // initialize encoder hardware\n  encoder.init();\n\n  // interrupt initialization\n  PciManager.registerListener(&listenerA);\n  PciManager.registerListener(&listenerB);\n\n  Serial.println(\"Encoder ready\");\n  _delay(1000);\n}\n\nvoid loop() {\n  // IMPORTANT - call as frequently as possible\n  // update the sensor values \n  encoder.update();\n\n  // display the angle and the angular velocity to the terminal\n  Serial.print(encoder.getAngle());\n  Serial.print(\"\\t\");\n  Serial.println(encoder.getVelocity());\n}\n```\n\nAlso, don't forget to test the sensor and make sure it's working properly before testing the driver. You can refer to the SimpleFOC documentation for more information on testing sensors and encoders: <https://docs.simplefoc.com/en/latest/getting_started/index.html#testing-the-sensor>.\n\nIf the problem persists, please provide more details about the hardware setup, error messages, or unexpected behavior you're experiencing."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 1"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC\\_AI: I see you're having trouble getting your code to work with the SimpleFOC library. Based on the provided code snippet, it seems you're trying to use an Encoder object without properly initializing it.\n\nFirst, let's make sure you have the library installed and the necessary hardware connected as mentioned on the SimpleFOC documentation (https://docs.simplefoc.com/).\n\nNow, in your code, replace \"sensor\" with \"encoder\". Also, make sure to change the impulses per revolution parameter accordingly:\n\n```cpp\nEncoder encoder = Encoder(2, 3, 500);\n// interrupt routine initialisation\nvoid doA(){encoder.handleA();}\nvoid doB(){encoder.handleB();}\n\nvoid setup() {\n  // monitoring port\n  Serial.begin(115200);\n\n  // initialize encoder hardware\n  encoder.init();\n  // hardware interrupt enable\n  encoder.enableInterrupts(doA, doB);\n\n  Serial.println(\"Encoder ready\");\n  _delay(1000);\n}\n\nvoid loop() {\n  // IMPORTANT\n  // read sensor and update the internal variables\n  encoder.update();\n  // display the angle and the angular velocity to the terminal\n  Serial.print(encoder.getAngle());\n  Serial.print(\"\\t\");\n  Serial.println(encoder.getVelocity());\n}\n```\n\nIf the issue still persists, make sure to verify the sensor pins' connections and check for any conflicts with other libraries or hardware. You might also want to go through the SimpleFOC documentation for sensors (https://docs.simplefoc.com/sensors/) to ensure you're using the correct parameters."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Output 2"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " SimpleFOC_AI: I see you're having trouble with your code not working as expected. Based on the provided code snippet, there are a few potential issues:\n\n1. Incorrect library inclusion: Make sure you have included the SimpleFOC library correctly at the beginning of your code with `#include <SimpleFOC.h>`.\n2. Incorrect sensor initialization: Instead of `sensor.init()`, it should be `encoder.init()`. The `encoder` variable is defined as an Encoder object.\n3. Incorrect pin numbers: Check that pins 2 and 3 are correctly connected to your encoder's A and B signals, respectively.\n4. Interrupt initialization: Ensure that you have the `PciManager` library installed and included correctly (`#include <PciManager.h>` and `#include <PciListenerImp.h>`) for software interrupts.\n5. Encoder object definition: You have a typo in your encoder definition, it should be `Encoder encoder = Encoder(2, 3, 500);` instead of `sensor.init();`.\n6. Call to update function: In the loop function, you need to call the update function for the encoder to get the latest readings, `encoder.update();`.\n\nMake sure to go through the [SimpleFOC Encoder documentation](https://docs.simplefoc.com/docs/classes/Encoder.html) for more information. If these suggestions don't help, you may need to provide more context, such as error messages or specific issues you are encountering."
          },
          "metadata": {}
        }
      ],
      "source": [
        "for question in questions:\n",
        "\n",
        "    response = query_engine.query(question)\n",
        "\n",
        "    prompt = create_prompt(query=question,\n",
        "                            context_items=[response.source_nodes[i].text for i in range(3)])\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    display(Markdown(f\"## User Question: {question}\"))\n",
        "    for sample_idx in range(n_samples):\n",
        "        outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"),\n",
        "                                temperature=0.7,\n",
        "                                do_sample=True,\n",
        "                                max_new_tokens=1024)\n",
        "        display(Markdown(f\"### Output {sample_idx}\"))\n",
        "        display(Markdown(tokenizer.batch_decode(outputs)[0][len(\"<s> \"+prompt):-len(\"</s>\")]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👉 The final test is pretty good here and deals efficiently with code 😎 Interestingly it even cought up a typo in a variable name that was done unintentionally by copying wrong code so pretty impressive. The only thing that is not very good here is that output 0 and 2 both mention to include PCIListener whereas it is actually not needed here."
      ],
      "metadata": {
        "id": "rnArON0YjEbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What's Next?\n",
        "\n",
        "Given the results on our little evaluation benchmark, there are several things that could be done to further improve the results:\n",
        "\n",
        "* Improve the chunking: having fixed-size chunks is quite rigid and sometimes results in important information being cut out from the chunk. For instance in test 5 the most important chunk from [this part](https://docs.simplefoc.com/sensors) of the docs is successfully retrieved, but it is cut before \"Hall sensors\" are mentionned, resulting in important loss of information in the generated output. We could have longer chunks but increasing length comes with additional cost and might not fit anymore in the context length. More advanced chunking methods might be useful here.\n",
        "* Improve the style of the answers: While I generally like the answers, there are still some undesired behaviors such as mention of context items or lengthy/generic answers. One way to improve that would be to further emphasize the desired style of answer in the base prompt. Another possibility would be to finetune the model on a database of the human query/answers which could be easily retrieved from the SimpleFOC docs.\n",
        "* Improve the docs: at the end this tool might be most useful for SimpleFOC maintainers to understand when the information is not so clearly explained in the docs in cases when the RAG pipeline fails to correctly answer a user query.\n",
        "\n",
        "Obviously all contributions and suggestions for improvements are very welcome! You can check the <span id=\"reprotext\">Github </span><span class=\"github-span\">Repository</span></a> and raise issues or suggest improvements if you have any 😀\n"
      ],
      "metadata": {
        "id": "vXYNJEzg5Rv0"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python [conda env:dsketch]",
      "language": "python",
      "name": "conda-env-dsketch-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}